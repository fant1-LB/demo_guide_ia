<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link type="text/css" rel="stylesheet" href="style.css">
    <script src="https://kit.fontawesome.com/cb0e37a241.js" crossorigin="anonymous"></script>
    <title>Exemples de projets</title>
</head>

<body>
    <header>
        <h1 id="Projets">Exemples de projets de traitement d’images par IA</h1>
    </header>
    <div class="flex">
        <section class="side">
            <ul>
                <li><a href="index.html">Accueil</a></li>
                <li><a href="lexique.html">Lexique</a></li>
                <li><a href="exemples.html">Exemples de projets</a></li>
                <li><a href="applications.html">Outils, guides et applications</a></li>
            </ul>
        </section>
        <section class="main">
            <h3 id="AUTOMATA">AUTOMATA</h3>
            <p>AUTOMATA, est une initiative européenne, à laquelle l’INRAP française est associée, qui vise à
                automatiser entièrement le processus de numérisation et de documentation de vestiges archéologiques
                lithiques et céramiques. Le projet inclut un volet robotique et mobilise des modèles IA pour
                analyser les objets traités et fournir facilement une grande quantité de données sur des corpus
                homogènes aux archéologues.</p><p>
                Pour plus d’information sur le projet AUTOMATA : <a
                    href="https://www.inrap.fr/automata-experimentation-de-numerisation-enrichie-automatisee-de-vestiges-20056"
                    target="_blank"
                    rel="noopener">https://www.inrap.fr/automata-experimentation-de-numerisation-enrichie-automatisee-de-vestiges-20056</a>
            </p>
            <h3 id="EIDA">EIDA</h3>
            <p>Le projet ANR EIDA, porté par le LIGM de l’école des Ponts et le SYRTE de l’observatoire de Paris. Ce
                projet a permis de mettre au point une plateforme (appelée Aikon) pour identifier et rapprocher des
                diagrammes astronomiques similaires dans des manuscrits eurasiens à travers les époques. L’IA a
                principalement été mobilisée pour extraire des diagrammes de manuscrits, puis identifier les diagrammes
                semblables. La diversité des sources mobilisées par le projet a forcé à des adaptations et à une
                représentation desdits diagrammes dans un espace vectoriel, pour que leur taille réelle soit ignorée par
                l’algorithme de similarité. La plateforme Aikon est aujourd’hui accessible en open-source, elle a depuis
                été améliorée pour les besoins d’autres projets.</p><p>
                Pour plus d’informations sur le projet EIDA : <a href="https://eida.hypotheses.org/" target="_blank"
                    rel="noopener">https://eida.hypotheses.org/</a></p>
            
            <h3 id="e-NDP">e-NDP</h3>
            <p> Le projet e-NDP, porté par le LAMOP de l'université Panthéon-Sorbonne t soutenu par l'Agence Nationale de la recherche
                est un projet de transcription et d'étude des registres et des livres du chapitre Notre-Dame de Paris du Moyen Age à l'époque moderne. 
                Ce projet allie un processus d'intelligence artificielle contrôlé par des chercheurs et ingénieurs, pour la transcription des dizaines de milliers de pages de ces documents, et 
                méthodes numériques plus classique (SIG, valorisation en ligne de documents) pour développer la connaissance du quartier médieval de la cathédrale. </p>
                <p>pour plus d'informations sur e-NDP : <a href="https://lamop.pantheonsorbonne.fr/e-ndp">https://lamop.pantheonsorbonne.fr/e-ndp </a> </p>        
            <h3 id="GallicaPix">GallicaPix</h3>
            <p>Le projet GallicaPix est un projet de la BNF, visant à faciliter la recherche dans les collections
                d’images de Gallica en mobilisant des outils IA. L’IA permet dans le cadre de ce projet d’affiner la
                recherche en déterminant le type d’objet physique qu’est l’image si la métadonnée est manquante, de lire
                les inscriptions sur l’image si le cas se présente, de repérer certains éléments figuratifs sur l’image,
                et de prendre en compte la structure de celle-ci (par exemple le découpage d’une affiche ou d’une page
                de journal).</p><p>
                Pour plus d’informations sur GallicaPix : <a
                    href="https://gallica.bnf.fr/accueil/fr/html/gallicapix-un-nouvel-outil-dexploration-iconographique"
                    target="_blank"
                    rel="noopener">https://gallica.bnf.fr/accueil/fr/html/gallicapix-un-nouvel-outil-dexploration-iconographique</a>
            </p>
            <h3 id="Highvision">Highvision</h3>
            <p>Ce projet ANR débuté en 2025 cherche à étudier la circulation des images des fonds des agences de presse
                dans les journaux du début du XXe siècle, il est réalisé en partenariat entre le laboratoire Echelles de
                l’université Paris Cité, le LIP6 de Sorbonne Université, le Lipade de Paris Descartes et le Service
                Historique de la Défense. Le projet mobilise l’IA pour retrouver les images d’agences de presses dans
                les journaux où elles ont été utilisées, mais aussi transcrire par exemple les commentaires de l’agence
                de presse, tenter d’associer les légendes attribuées par les journaux à chaque image, et même
                potentiellement identifier les retouches dont elles ont été la cible.</p><p>
                Pour plus d’informations sur le projet Highvision : <a href="https://highvision.hypotheses.org/"
                    target="_blank" rel="noopener">https://highvision.hypotheses.org/</a></p>
            <h3 id="HikarIA">HikarIA</h3>
            <p>Le projet Hikaria, mené au musée Guimet en partenariat avec la société TEKLIA, a permis le développement
                d’une plateforme visant à mettre en valeur les photographies du Japon de la fin du XIXe siècle des
                carnets Dubois (17 000 images) et d’autres sources en ligne. Dans le cadre de ce projet l’IA a été
                mobilisée avec un grand succès pour extraire les photos des carnets numérisés et rapprocher les images
                se ressemblant les unes des autres. Le projet a aussi tenté d’attribuer automatiquement grâce à un LLM
                génératif un ensemble de “tags” aux images venant compléter les classifications faites par des humains,
                avec des résultats de qualité variable.</p><p>
                Pour plus d’informations sur HikarIA : <a href="https://hikaria.org/" target="_blank"
                    rel="noopener">https://hikaria.org/</a></p>
            <h3 id="TORNE-H">TORNE-H</h3>
            <p>TORNE-H est un projet de computer vision et d’introduction de l’IA dans des collections muséales. Pendant
                un an le projet s’est établi sur les collections du Musée des Arts Décoratifs. Il a deux buts principaux
                : développer un modèle de reconnaissance par ordinateur entraîné sur la collection du designer Jean
                Royère afin d’identifier les modèles et les spécificités des meubles de Royère à partir de gouaches, de
                calques d’exécutions et de photographies noir et blanc. Et deuxièmement de former, d’informer et de
                formuler en des termes informatiques les besoins métiers des conservateurs et conservatrices du musée
                dans leur gestion au quotidien des collections. En cela, le projet explore tout aussi bien les limites
                matérielles qu’humaines qui entourent l’introduction de l’IA au musée, avec les enjeux que posent la
                dette technique d’une institution ou les exigences de scientificité du travail de conservation.</p>
            <p>Pour plus d’informations sur le projet Torne-H : <a
                    href="https://www.chartes.psl.eu/recherche/centre-jean-mabillon/projets-de-recherche/torne-h-traitement-dobjets-par-reconnaissance-numerique-en-environnement-humain-henrot"
                    target="_blank"
                    rel="noopener">https://www.chartes.psl.eu/recherche/centre-jean-mabillon/projets-de-recherche/torne-h-traitement-dobjets-par-reconnaissance-numerique-en-environnement-humain-henrot</a>
            </p>
            <h3 id="Ukiyo-e">Ukiyo-e</h3>
            <p>Ukiyo-e est un projet de base de données d’estampes japonaises remontant à 2012. Une technologie appelée
                le “MatchEngine” est mobilisé dans son cadre pour retrouver des estampes similaires parmi la base de 200
                000 estampes que la plateforme contient, permettant aux chercheurs et aux chercheuses d’étudier les
                copies et les circulations des motifs à travers l’espace et le temps. C’est un exemple typique de
                réalisation pour laquelle on pourrait être tenté d’utiliser un outil IA mais où ce n’était pas
                nécessaire.</p><p>
                La plateforme ukiyo-e : <a href="https://fr.ukiyo-e.org/" target="_blank"
                    rel="noopener">https://fr.ukiyo-e.org/</a></p>
        </section>
    </div>
</body>

</html>