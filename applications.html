<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link type="text/css" rel="stylesheet" href="style.css">
    <script src="https://kit.fontawesome.com/cb0e37a241.js" crossorigin="anonymous"></script>
    <title>Applications</title>
</head>

<body>
    <header>
        <h1>Outils, guides et applications</h1>
    </header>
    <div class="flex">
        <section class="side">
            <ul>
                <li><a href="index.html">Accueil</a></li>
                <li><a href="lexique.html">Lexique</a></li>
                <li><a href="exemples.html">Exemples de projets</a></li>
                <li>
                    <a href="applications.html">Outils, guides et applications</a>
                    <ul>
                        <li>
                            <a href="applications.html#ressources">Ressources utiles</a>
                        </li>
                        <li>
                            <a href="applications.html#applications">Applications</a>
                        </li>
                    </ul>
                </li>
            </ul>


        </section>
        <section class="main">
            <h2 id="ressources">Ressources utiles</h2>
            <h3 id="googleMG">Le Google Machine Glossary</h3>
            <p>Lien : <a href="https://developers.google.com/machine-learning/glossary"
                    target="_blank">https://developers.google.com/machine-learning/glossary</a>
            </p>
            <p>Ce glossaire extrêmement complet, contient à peu près tous les termes et expressions relatifs au
                <em>machine learning</em> dont vous pourriez avoir besoin. Il faut noter cependant qu’il a été rédigé en
                anglais et que la traduction française n’est pas toujours très bonne. Destiné à des développeurs, les
                définitions sont également parfois complexes d’un point de vue technique.
            </p>
            <h3 id="lexiquePictorIA">Lexique : notions générales, de PictorIA
            </h3>
            <p>Lien : <a href="https://pictoria.hypotheses.org/1673"
                    target="_blank">https://pictoria.hypotheses.org/1673</a></p>
            <p>
                Ce Lexique, plus court que le glossaire Google, mais tout de même bien fourni, a été réalisé par Jean
                Christophe Carius, du service numérique de la recherche de l’INHA pour le compte de PictorIA. Il a été
                rédigé en français et évite donc les problèmes de traduction de celui de Google.</p>
            <h3 id="AIframework">Le “AI
                framework” du laboratoire de la bibliothèque du congrès américain</h3>
            <p>Lien : <a href="https://github.com/LibraryOfCongress/labs-ai-framework"
                    target="_blank">https://github.com/LibraryOfCongress/labs-ai-framework</a> </p>
            <p>
                Ce Repository Github contient un guide de la Librairie du Congrès américaine consacré à l’usage de l’IA
                dans les institutions patrimoniales. Il découpe les problématiques de l’IA en notions simples
                généralisables à la plupart des usages et fournit un ensemble de fiches à remplir pour cadrer les enjeux
                et défis d’un potentiel projet. Ce “Framework” a été traduit par Jean Phillipe Moreux de la Bibliothèque
                Nationale de France, la traduction est disponible <a
                    href="https://github.com/altomator/Planification-de-projets-IA">ici</a>.</p>
            <h3 id="Huggingface">Huggingface</h3>
            <p>Lien : <a href="https://huggingface.co/" target="_blank">https://huggingface.co/</a> </p>
            <p> Cette plateforme mise en place par une entreprise privée sert de dépôt pour les chercheurs et
                chercheuses utilisant l’IA du monde entier. Elle contient des centaines de modèles IA et de jeux de
                données, disponibles au téléchargement. Elle permet aussi, via des appels d’API, d’intégrer directement
                des jeux de données ou des modèles IA à votre code.</p>
            <h3 id="HTRUnited">HTR-United</h3>
            <p>Lien : <a href="https://htr-united.github.io/index.html"
                    target="_blank">https://htr-united.github.io/index.html</a> </p>
            <p>
                Cette plateforme mise en place par une équipe de l’INRIA a pour objectif de rassembler et mettre à
                disposition le plus possible de jeux de données utilisables dans le cadre de projets d’HTR (Handwritten
                Text Recognition, ou transcritpion automatique d’écriture manuscrite). Elle fonctionne sur une base
                participative, les <em>datasets</em> sont partagés par les différents projets et ensuite récupérables
                sur la plateforme pour être réutilisés.</p>
            <h3 id="MuseumAINetwork">The Museum + AI network</h3>
            <p>Lien : <a href="https://themuseumsai.network/" target="_blank">https://themuseumsai.network/</a> </p>
            <p>
                Ce site web contient les travaux d’une initiative universitaire anglaise en faveur d’un usage
                intelligent de l’IA dans les musées. Leur “Toolkit”, où boîte à outils, de la même manière que le
                “framework” de la librairie du Congrès, présente de manière pédagogique les enjeux et problématiques
                inhérentes à la réalisation d’un projet IA dans un contexte muséal. Si les exemples de projet donnés
                dans le “Toolkit” concernent plus l’application de l’IA dans un contexte de gestion du musée que des
                collections comme c’est le cas dans la plupart des projets que nous présentons, le cadre théorique qu’il
                présente reste globalement pertinent pour tout projet IA. Il n’est aujourd’hui pas traduit en Français.
            </p>
            <h3 id="AIforLAM">Awesome AI for LAM</h3>
            <p>Lien : <a href="https://ai4lam.github.io/awesome-ai4lam/"
                    target="_blank">https://ai4lam.github.io/awesome-ai4lam/</a> </p>
            <p>
                Ce site a été créé par la communauté AI4LAM (LAM étant l’acronyme anglais de Librairies - Archives -
                Museums), une communauté internationale rassemblant des professionnels de ces milieux et d’informatique
                consacrée aux usages de l’IA dans le contexte patrimonial. Le site contient une liste très fournie de
                liens vers des matériaux d’apprentissage, outils, jeux de données, recommandations, publications ou
                encore exemples de projets consacrés à l’utilisation de l’IA dans le contexte patrimonial. Le site n’est
                pas traduit en français.</p>


            <h2 id="applications">Liste d’applications</h2>
            <p>Cette section du guide présente un ensemble d’outils pouvait permettre de traiter des images par IA.
                Leurs statuts sont très variables, certains sont développés par des entreprises privées, d’autre non,
                certains sont open-source, d’autres propriétaires, certains sont installés en local, d’autres sur les
                serveurs de l’institution qui les utilise, d’autres encore une plateforme en ligne… Cette liste n’est
                pas exhaustive et est principalement basée sur le point commun de leur usage au sein de PictorIA et de
                ses partenaires.</p>
           
            <h3 id="Panoptic">Panoptic</h3>
             <ul>
                <li>Ouverture : 🔓 </li>
                <li>Origine : 🇫🇷 </li>
                <li>Difficulté : ⭐</li>
            </ul>
            <p>Cette application a été développée par le CERES de l’université Paris Panthéon-Sorbonne. Facile d’usage,
                elle permet de très rapidement trier et annoter des corpus d’image massifs. Elle utilise le moteur CLIP
                pour rassembler des images en “clusters” sur la base de leur ressemblance où à partir de langage
                naturel. Les utilisateurs et utilisatrices ont ensuite la possibilité d’associer des mots clés aux
                images en fonction des résultats de ces manipulations, où à la main directement.<br>
                L’application est gratuite. L’application est open source. L’application ne demande pas un bon niveau en
                informatique. L’application ne demande pas de GPU.<br>
                Documentation de Panoptic : <a href="https://ceres.sorbonne-universite.fr/Panoptic/"
                    target="_blank">https://ceres.sorbonne-universite.fr/Panoptic/</a></p>
            <h3 id="Labelstudio">Labelstudio</h3>
            <ul>
                <li>Ouverture : 🔒 </li>
                <li>Origine : 🇺🇸 </li>
                <li>Difficulté : ⭐⭐</li>
            </ul>

            <p>Cette application a été développée par l’entreprise HumanSignal, elle permet d’annoter manuellement selon
                différentes modalités (<em>bounding boxes</em>, <em>masks</em>, polygones…). Elle permet également de
                tester en direct des modèles de <em>computer vision</em> sur des images sans réentraînement, même si
                l’implémentation desdits modèles est plutôt complexe. Cette application est un bon outil pour
                l’annotation de corpus d’images pour l’entraînement ou l’évaluation de modèles de <em>computer
                    vision</em>.<br>
                L’application est gratuite, mais l’entreprise propose une version payante avec support et hébergement
                intégré. L’application est open source. L’installation de l’application et l’implémentation
                (facultative) de modèles en son sein demandent un bon niveau technique, l’utilisation pour la seule
                annotation est simple. L’application ne demande pas de GPU pour les tâches d’annotation.<br>
                Documentation de LabelStudio: <a href="https://labelstud.io/guide/"
                    target="_blank">https://labelstud.io/guide/</a></p>
            <h3 id="Arkindex">Arkindex</h3>
             <ul>
                <li>Ouverture : 🔒/🔓 </li>
                <li>Origine : 🇫🇷 </li>
                <li>Difficulté : ⭐⭐⭐</li>
            </ul>
            <p>Cette application a été développée par l’entreprise Teklia, elle permet d’appliquer différents
                traitements IA à des images via des <em>workers</em> développés par l’entreprise ou personnalisés. Les
                traitements en question vont de tâches d’OCR simples à des inférences LLM en passant par des détections
                automatiques d’objets. L’application permet également de réaliser des annotations d’images en vue du
                réentraînement ou de l’évaluation de modèles de <em>computer vision</em>. Arkindex peut fonctionner en
                tandem avec l’application Callico, qui permet d’organiser des campagnes collaboratives d’annotation à
                grande échelle.<br>
                La base de l’application est gratuite, mais l’entreprise propose de payer pour ses services de support,
                d’hébergement et de travail sur les <em>workers</em>. L’application est open source. Le déploiement de
                l’application demande un bon niveau d’informatique, l’utilisation des <em>workers</em> demande un niveau
                variable selon les usages, l’annotation est plutôt simple, l’annotation dans Callico est très simple.
                L’application demande un GPU pour la plupart des tâches.<br> Documentation d’Arkindex: <a
                    href="https://doc.teklia.com/arkindex/" target="_blank">https://doc.teklia.com/arkindex/</a>
                <br>Documentation de Callico: <a href="https://doc.teklia.com/callico/"
                    target="_blank">https://doc.teklia.com/callico/</a>
            </p>
            <h3 id="Aikon">Aikon</h3>
             <ul>
                <li>Ouverture : 🔓 </li>
                <li>Origine : 🇫🇷 </li>
                <li>Difficulté : ⭐⭐⭐</li>
            </ul>
            <p>Cette application a été développée en marge du projet ECR Discover par des équipes de l’école des ponts
                et de l’observatoire de Paris, elle est destinée à l’étude de larges corpus historiques grâce aux
                possibilités de la <em>Computer Vision</em> par IA. L’application permet ainsi d’extraire les
                illustrations d’images contenant illustration et texte, de chercher des motifs similaires d’un document
                à un autre ou encore de retrouver des motifs à partir de modèles pré-entraînés.<br>
                L’application est gratuite, avec la possibilité de demander l’accès à une plateforme de test.
                L’application est open source. Le déploiement de l’application est complexe, son usage est relativement
                simple. L’application peut demander un GPU ou non selon les modèles que l’on veut appliquer.<br>
                Présentation d'Aikon : <a href="https://aikon-platform.github.io/">https://aikon-platform.github.io/</a>
            </p>

                <h3 id="Arvest">Arvest</h3>
             <ul>
                <li>Ouverture : 🔓 </li>
                <li>Origine : 🇫🇷 </li>
                <li>Difficulté : ⭐⭐⭐⭐</li>
            </ul>
            <p>Cette application a été développée dans le cadre du projet STAGE, "From stage to data", de l'université Rennes 2.
                Son objectif est de permettre la transformation en données structurées de médias variés (images, vidéo, son),
                 pour permettre ensuite des études quantitatives sur des grands corpus. L'application a d'abord été développée pour l'étude du théâtre. <br>
                L’application est gratuite, avec la possibilité de demander l’accès à une plateforme de test.
                L’application est open source. Le déploiement de l’application est complexe, son usage est relativement
                complexe. <br>
               Présentation d'Arvest : <a href="https://arvest.app/fr">https://arvest.app/fr</a>
            </p>
            <ul>
                <li>Liste d’outils : roboflow?/escriptorium/transkribus/pixplot/solutions notebooks / Arvest / Gradio ?
                    /</li>
            </ul>
        </section>
    </div>
</body>

</html>